{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error functions\n",
    "def introduce_typo(word):\n",
    "    if len(word) > 1:\n",
    "        pos = random.randint(0, len(word) - 1)\n",
    "        return word[:pos] + random.choice('abcdefghijklmnopqrstuvwxyz') + word[pos + 1:]\n",
    "    return word\n",
    "\n",
    "def replace_accent(word):\n",
    "    accents = {'a': 'áàảãạâấầẩẫậăắằẳẵặ', 'e': 'éèẻẽẹêếềểễệ', 'i': 'íìỉĩị', \n",
    "               'o': 'óòỏõọôốồổỗộơớờởỡợ', 'u': 'úùủũụưứừửữự', 'y': 'ýỳỷỹỵ'}\n",
    "    for char in word:\n",
    "        if char in accents:\n",
    "            word = word.replace(char, random.choice(accents[char]))\n",
    "    return word\n",
    "\n",
    "def typo_phonetic(word):\n",
    "    phonetic_dict = {'ch': 'tr', 'tr': 'ch', 's': 'x', 'x': 's', 'r': 'd', 'd': 'r'}\n",
    "    for k, v in phonetic_dict.items():\n",
    "        if k in word:\n",
    "            return word.replace(k, v)\n",
    "    return word\n",
    "\n",
    "def split_word(word):\n",
    "    if len(word) > 3:\n",
    "        pos = random.randint(1, len(word) - 2)\n",
    "        return word[:pos] + ' ' + word[pos:]\n",
    "    return word\n",
    "\n",
    "def merge_words(words):\n",
    "    if len(words) > 1:\n",
    "        pos = random.randint(0, len(words) - 2)\n",
    "        return words[:pos] + [words[pos] + words[pos + 1]] + words[pos + 2:]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting text from data collection\n",
    "def get_texts(texts_folder):\n",
    "    alltext_lines=[]\n",
    "    texts = []\n",
    "\n",
    "    files = os.listdir(texts_folder)\n",
    "\n",
    "    for file in files:\n",
    "        if os.path.isfile(os.path.join(texts_folder, file)):\n",
    "            # Read files\n",
    "            with open(os.path.join(texts_folder,file), 'r', encoding='utf-8') as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            alltext_lines.append(line)\n",
    "\n",
    "    # Remove '#' if exists\n",
    "    texts = [line.strip() for line in alltext_lines if not line.startswith('#') and line.strip() != '']\n",
    "\n",
    "    return texts\n",
    "\n",
    "#Create error func\n",
    "def create_error_sentence(sentence):\n",
    "    words = sentence.split()\n",
    "    error_sentence = []\n",
    "    for word in words:\n",
    "        prob = random.random()\n",
    "        if prob < 0.2:  # 20% of the sentence will be BING BONG!!!\n",
    "            error_word = random.choice([introduce_typo, replace_accent, typo_phonetic, split_word])(word)\n",
    "            error_sentence.append(error_word)\n",
    "        else:\n",
    "            error_sentence.append(word)\n",
    "    \n",
    "    # Merge words\n",
    "    if random.random() < 0.1:\n",
    "        error_sentence = merge_words(error_sentence)\n",
    "        \n",
    "    return ' '.join(error_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(texts_folder):\n",
    "    # generate both normal texts and errored texts\n",
    "    texts = get_texts(texts_folder)\n",
    "    error_texts = [create_error_sentence(text) for text in texts]\n",
    "    \n",
    "    texts_train, texts_test, error_texts_train, error_texts_test = train_test_split(texts, error_texts, test_size=0.2,random_state=42)\n",
    "\n",
    "    # save train df to train.csv\n",
    "    train_data = {'original': texts_train, 'error': error_texts_train}\n",
    "    df = pd.DataFrame(train_data)\n",
    "    df.to_csv('train.csv', index=False)\n",
    "\n",
    "    #save test df to test.csv\n",
    "    test_data = {'original': texts_test, 'error': error_texts_test}\n",
    "    df = pd.DataFrame(test_data)\n",
    "    df.to_csv('test.csv', index=False)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               original  \\\n",
      "0     Đó là Nguyễn Cường, Trương Ngọc Ninh, Bảo Chấn...   \n",
      "1     Tuy nhiên, các dấu vết thu được trên quần áo c...   \n",
      "2     Điều quan trọng hơn là ngành GD-ĐT cần chấn ch...   \n",
      "3     Giờ đây, chính nhưng căn phòng ấy trong bệnh v...   \n",
      "4     Cá nhân tôi cho rằng game online vẫn còn là hì...   \n",
      "...                                                 ...   \n",
      "4020  Một nhóm những người chuyển giới ở Ấn Độ đang ...   \n",
      "4021  Nhờ vai diễn này, Kim Jung Eun đoạt giải thưởn...   \n",
      "4022  Các hộ thanh niên vào làng tham gia lập nghiệp...   \n",
      "4023  Quang Huy lồng hình khối của tháp Chàm vào nét...   \n",
      "4024  Điều đó chỉ khiến bé tò mò tự hỏi phải chăng v...   \n",
      "\n",
      "                                                  error  \n",
      "0     Đó là Nguyễn Cường, Trương Ngọc Ninh, Bảo Chấn...  \n",
      "1     Tuy nhiên, các dấu vết thử được trên quần áo c...  \n",
      "2     Điều quan trọng hơn là ngành GD-ĐT cần chấn ch...  \n",
      "3     Giờ đây, chính n hưng căn phòng ấy trong bệnh ...  \n",
      "4     Cá nhân tôi cho rằng game online vẫn còn là hì...  \n",
      "...                                                 ...  \n",
      "4020  Mộtnhóm những người chuyển giới ở Ấn Độ đang t...  \n",
      "4021  Nhờ vai diễn này, Kim Jung Eun đoạt giải thưởn...  \n",
      "4022  Các hộ thanh niên vào làng tham gia lập nghiệp...  \n",
      "4023  Q uang Huy lồng hình khối của tháp Ch àm vào n...  \n",
      "4024  Điều đó chỉ khiến bé tò mò tự hỏi phải chăng v...  \n",
      "\n",
      "[4025 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(get_df('data_collection'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
